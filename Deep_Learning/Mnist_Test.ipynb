{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import all libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from Mnist_Classifier_SNN import MNIST_SNN\n",
    "from Mnist_Classifier_CNN import MNIST_CNN\n",
    "from Mnist_Classifier_NN import MNIST_NN\n",
    "\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error as mse"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Check if GPU is available"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import ray\n",
    "# import os\n",
    "# import random\n",
    "# import sys\n",
    "#\n",
    "# def init_cluster():\n",
    "#     ray.init(address='auto')\n",
    "#     print(f\"This cluster consists of {len(ray.nodes())} nodes and \"\n",
    "#           f\"{ray.cluster_resources()['CPU']} CPUs in total.\")\n",
    "#     return int(ray.cluster_resources()['CPU'])\n",
    "#\n",
    "#\n",
    "# @ray.remote\n",
    "# def throw_points(n):\n",
    "#     print(f\"{os.getpid()} on {os.uname().nodename} is started\")\n",
    "#     i = 0\n",
    "#     for _ in range(n):\n",
    "#         x = random.uniform(-1, 1)\n",
    "#         y = random.uniform(-1, 1)\n",
    "#         if x**2 + y**2 <= 1:\n",
    "#             i += 1\n",
    "#     print(f\"{os.getpid()} on {os.uname().nodename} is finished\")\n",
    "#     return i\n",
    "#\n",
    "#\n",
    "# def main():\n",
    "#     sys.stderr = open(os.devnull, \"w\")\n",
    "#     number_of_cpu = init_cluster()\n",
    "#     n = 10000000\n",
    "#     inner = ray.get([throw_points.remote(n) for _ in range(number_of_cpu)])\n",
    "#     pi = 4 * sum(inner) / (number_of_cpu*n)\n",
    "#     print(f\"Estimated Pi value is {pi:.8f}\")\n",
    "#\n",
    "#\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if device.type == 'cuda':\n",
    "    !nvidia-smi\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print(\"No GPU :(\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load MNIST dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.MNIST(root = 'datasets', train = True, download = True, transform=torchvision.transforms.ToTensor())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Get and visualize random individual"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rand_individ = random.randint(0, 60_000)\n",
    "img = dataset[rand_individ][0].view((28, 28))\n",
    "ans = dataset[rand_individ][1]\n",
    "plt.imshow(img, cmap='Greys')\n",
    "plt.xlabel(f\"NUMBER: {ans}\")\n",
    "pass"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prepare and split data into train/test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: datasets\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n"
     ]
    }
   ],
   "source": [
    "split_ratio = 0.90\n",
    "batch_size = 50\n",
    "train_size = round(len(dataset) * split_ratio)\n",
    "valid_size = len(dataset) - train_size\n",
    "\n",
    "# print(dataset.shape)\n",
    "print(dataset)\n",
    "\n",
    "train, valid = torch.utils.data.random_split(dataset, [train_size, valid_size])\n",
    "\n",
    "train_batch_loader = torch.utils.data.DataLoader2(train, batch_size=batch_size, collate_fn=lambda x: tuple(x_.to(device) for x_ in torch.utils.data.dataloader.default_collate(x)))\n",
    "valid_batch_loader = torch.utils.data.DataLoader2(valid, batch_size=batch_size, collate_fn=lambda x: tuple(x_.to(device) for x_ in torch.utils.data.dataloader.default_collate(x)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Configure NN Model and hyper-parameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mnist_nn = MNIST_NN(28*28, 10).to(device)\n",
    "\n",
    "epochs = 5\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.ASGD(mnist_nn.parameters(), lr=0.8)\n",
    "\n",
    "history = []\n",
    "summary(mnist_nn, (28*28,), batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train loop"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_mnist_NN():\n",
    "    for epoch in range(0, epochs):\n",
    "        for i, (features, ans) in enumerate(tqdm(train_batch_loader)):\n",
    "            # Forward pass\n",
    "            Y_pred = mnist_nn.forward(features.view(-1, 28*28))\n",
    "\n",
    "            loss = loss_func(Y_pred, ans)\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if i % 3 == 0: history.append(loss.data)\n",
    "\n",
    "train_mnist_NN()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training via RAY Cluster\n",
    "* Firstly install corresponding version of python to each cluster node `python 3.7.13`.\n",
    "* Install ray by `python3.7 -m pip install ray[default]`, not `ray`, cuz rather dashboard would not work. If you already have it installed, don't forget to update by `pip install -U ray[default]`.\n",
    "* Start the cluster head node via ray CLI mode: `ray start --head`.\n",
    "* The dashboard would be available on `http://localhost:8265/`.\n",
    "* Add other nodes the same by CLI mode: `ray start --address=''`.\n",
    "\n",
    "After that you would be able to execute this code:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import ray\n",
    "from ray import train\n",
    "from ray.air import session, Checkpoint\n",
    "from ray.train.torch import TorchTrainer\n",
    "from ray.air.config import ScalingConfig\n",
    "\n",
    "\n",
    "def train_loop_per_worker():\n",
    "    dataset_shard = session.get_dataset_shard(\"train\")\n",
    "\n",
    "    model = ray.train.torch.prepare_model(mnist_nn)\n",
    "\n",
    "    for epoch in range(0, epochs):\n",
    "        for batches in dataset_shard.iter_torch_batches(batch_size=batch_size, dtypes=torch.float):\n",
    "            inputs, labels = torch.unsqueeze(batches[\"x\"], 1), batches[\"y\"]\n",
    "            output = model(inputs)\n",
    "            loss = loss_func(output, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            print(f\"epoch: {epoch}, loss: {loss.item()}\")\n",
    "\n",
    "        session.report(\n",
    "            {},\n",
    "            checkpoint=Checkpoint.from_dict(\n",
    "                dict(epoch=epoch, model=model.state_dict())\n",
    "            ),\n",
    "        )\n",
    "\n",
    "\n",
    "train_dataset = train.torch.prepare_data_loader(train_batch_loader)\n",
    "valid_dataset = train.torch.prepare_data_loader(valid_batch_loader)\n",
    "\n",
    "scaling_config = ScalingConfig(num_workers=3)\n",
    "# If using GPUs, use the below scaling config instead.\n",
    "# scaling_config = ScalingConfig(num_workers=3, use_gpu=True)\n",
    "trainer = TorchTrainer(\n",
    "    train_loop_per_worker=train_loop_per_worker,\n",
    "    scaling_config=scaling_config,\n",
    "    datasets={\"train\": train_dataset},\n",
    ")\n",
    "result = trainer.fit()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(list(map(lambda x: x.cpu(), history)))\n",
    "print(f\"Mean CrossEntropyLoss (last 100): {sum(history[-100:]) / 100}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Validation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    answers = torch.zeros(10).to(device)\n",
    "    predictions = torch.zeros(10).to(device)\n",
    "\n",
    "    for i, (features, ans) in enumerate(tqdm(valid_batch_loader)):\n",
    "        predictions = torch.vstack((predictions, nn.functional.normalize(mnist_nn(features.view(-1, 28*28)))))\n",
    "\n",
    "        # Convert to one-hot encoded\n",
    "        ans = nn.functional.one_hot(ans, num_classes=10)\n",
    "\n",
    "        answers = torch.vstack((answers, ans))\n",
    "\n",
    "    print(f\"MSE: {mse(predictions.T.cpu(), answers.T.cpu())}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Visualisation test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rand_individ = random.randint(0, 60_000)\n",
    "img = dataset[rand_individ][0].view((28, 28))\n",
    "ans = dataset[rand_individ][1]\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred = mnist_nn(img.to(device).view(-1)).argmax()\n",
    "\n",
    "plt.imshow(img, cmap='Greys')\n",
    "plt.xlabel(f\"PREDICTION: {pred}, ANSWER {ans}\")\n",
    "pass "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Configure CNN Model and hyper-parameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mnist_cnn = MNIST_CNN().to(device)\n",
    "\n",
    "epochs = 2\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(mnist_cnn.parameters(), lr=0.01)\n",
    "\n",
    "history = []\n",
    "summary(mnist_cnn, (1, 28, 28), batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train loop"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for epoch in range(0, epochs):\n",
    "    for i, (features, ans) in enumerate(tqdm(train_batch_loader)):\n",
    "        # Forward pass\n",
    "        Y_pred = mnist_cnn.forward(features.view(-1, 1, 28, 28))\n",
    "        # print(Y_pred.shape)\n",
    "\n",
    "        loss = loss_func(Y_pred, ans)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if i % 3 == 0: history.append(loss.data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(list(map(lambda x: x.cpu(), history)))\n",
    "print(f\"Mean CrossEntropyLoss (last 100): {sum(history[-100:]) / 100}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Validation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    answers = torch.zeros(10).to(device)\n",
    "    predictions = torch.zeros(10).to(device)\n",
    "\n",
    "    for i, (features, ans) in enumerate(tqdm(valid_batch_loader)):\n",
    "        predictions = torch.vstack((predictions, nn.functional.normalize(mnist_cnn(features.view(-1, 1, 28, 28)))))\n",
    "\n",
    "        # Convert to one-hot encoded\n",
    "        ans = nn.functional.one_hot(ans, num_classes=10)\n",
    "\n",
    "        answers = torch.vstack((answers, ans))\n",
    "\n",
    "    print(f\"MSE: {mse(predictions.T.cpu(), answers.T.cpu())}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
